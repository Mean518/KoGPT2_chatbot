{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597659341509",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers, losses, metrics\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25}\n"
    }
   ],
   "source": [
    "# 캐릭터 글자 목록\n",
    "char_list = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', \n",
    "             'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "\n",
    "# 캐릭터 사전 생성\n",
    "# index순서대로 부여\n",
    "char_to_idx = {c: i for i, c in enumerate(char_list)}\n",
    "dic_len = len(char_to_idx)\n",
    "\n",
    "print(char_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 목록\n",
    "# 앞의 세 글자가 주어지면 마지막 글자를 예측\n",
    "# lov -> e\n",
    "word_list = ['love', 'look', 'face', 'fast', 'home', 'hope',\n",
    "             'good', 'gold', 'tree', 'true', 'road', 'rock']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치 데이터 생성\n",
    "def make_batch(word_list):\n",
    "    \n",
    "    input_batch = []\n",
    "    target_batch = []\n",
    "\n",
    "    for word in word_list:\n",
    "        # 입력 단어를 인덱스로 변환\n",
    "        input = [char_to_idx[c] for c in word[:-1]]\n",
    "        \n",
    "        # 목표 캐릭터를 인덱스로 변환\n",
    "        target = char_to_idx[word[-1]]\n",
    "\n",
    "        # 입력 인덱스를 원핫인코딩으로 변환\n",
    "        # 암배당 안하고 원핫인코딩\n",
    "        input_batch.append(np.eye(dic_len)[input])\n",
    "\n",
    "        # 목표 인덱스를 원핫인코딩으로 변환\n",
    "        target_batch.append(np.eye(dic_len)[target])\n",
    "\n",
    "    return np.array(input_batch), np.array(target_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[11, 14, 21]"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "[char_to_idx[c] for c in 'love'[:-1]] # l:11, o:14, v:21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[1., 0., 0., ..., 0., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 1., 0., 0.],\n       [0., 0., 0., ..., 0., 1., 0.],\n       [0., 0., 0., ..., 0., 0., 1.]])"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "# 단위행렬, 정방행렬 생성\n",
    "# np.identity는 단위행렬\n",
    "# np.eye는 대각선인 1인 대각행렬 생성\n",
    "np.eye(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "np.eye(dic_len)[[char_to_idx[c] for c in 'love'[:-1]]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력/목표 배치 생성\n",
    "x_train, y_train = make_batch(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.])"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "y_train[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(12, 3, 26)"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "x_train.shape # 단어 12개, time_step=3, 단어 사전 길이: 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세 글자만큼 타임스텝 반복\n",
    "time_step = 3\n",
    "\n",
    "def build_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, input_shape = (time_step, dic_len)))\n",
    "    model.add(Dense(dic_len, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    \n",
    "    return model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlstm (LSTM)                  (None, 64)                23296     \n_________________________________________________________________\ndense (Dense)                (None, 100)               6500      \n_________________________________________________________________\ndense_1 (Dense)              (None, 26)                2626      \n=================================================================\nTotal params: 32,422\nTrainable params: 32,422\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# summary보기 위해서 따로 출력\n",
    "time_step = 3\n",
    "dic_len = 26\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(time_step, dic_len)))\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(dic_len, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 훈련 및 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/100\n12/12 [==============================] - 0s 1ms/step - loss: 3.2511 - acc: 0.0833\nEpoch 2/100\n12/12 [==============================] - 0s 1ms/step - loss: 3.1699 - acc: 0.5833\nEpoch 3/100\n12/12 [==============================] - 0s 1ms/step - loss: 3.0953 - acc: 0.5000\nEpoch 4/100\n12/12 [==============================] - 0s 1ms/step - loss: 3.0036 - acc: 0.5000\nEpoch 5/100\n12/12 [==============================] - 0s 1ms/step - loss: 2.8798 - acc: 0.5000\nEpoch 6/100\n12/12 [==============================] - 0s 1ms/step - loss: 2.7083 - acc: 0.5000\nEpoch 7/100\n12/12 [==============================] - 0s 1ms/step - loss: 2.4683 - acc: 0.5000\nEpoch 8/100\n12/12 [==============================] - 0s 914us/step - loss: 2.1592 - acc: 0.5000\nEpoch 9/100\n12/12 [==============================] - 0s 997us/step - loss: 1.8281 - acc: 0.5000\nEpoch 10/100\n12/12 [==============================] - 0s 997us/step - loss: 1.5732 - acc: 0.5000\nEpoch 11/100\n12/12 [==============================] - 0s 997us/step - loss: 1.4176 - acc: 0.5000\nEpoch 12/100\n12/12 [==============================] - 0s 1ms/step - loss: 1.3233 - acc: 0.5000\nEpoch 13/100\n12/12 [==============================] - 0s 1ms/step - loss: 1.2616 - acc: 0.5000\nEpoch 14/100\n12/12 [==============================] - 0s 997us/step - loss: 1.1988 - acc: 0.5000\nEpoch 15/100\n12/12 [==============================] - 0s 997us/step - loss: 1.1423 - acc: 0.5000\nEpoch 16/100\n12/12 [==============================] - 0s 997us/step - loss: 1.0922 - acc: 0.5000\nEpoch 17/100\n12/12 [==============================] - 0s 914us/step - loss: 1.0418 - acc: 0.6667\nEpoch 18/100\n12/12 [==============================] - 0s 997us/step - loss: 0.9977 - acc: 0.6667\nEpoch 19/100\n12/12 [==============================] - 0s 997us/step - loss: 0.9497 - acc: 0.6667\nEpoch 20/100\n12/12 [==============================] - 0s 997us/step - loss: 0.9107 - acc: 0.6667\nEpoch 21/100\n12/12 [==============================] - 0s 914us/step - loss: 0.8561 - acc: 0.6667\nEpoch 22/100\n12/12 [==============================] - 0s 997us/step - loss: 0.8251 - acc: 0.6667\nEpoch 23/100\n12/12 [==============================] - 0s 997us/step - loss: 0.7800 - acc: 0.6667\nEpoch 24/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.7362 - acc: 0.6667\nEpoch 25/100\n12/12 [==============================] - 0s 997us/step - loss: 0.6962 - acc: 0.7500\nEpoch 26/100\n12/12 [==============================] - 0s 997us/step - loss: 0.6698 - acc: 0.7500\nEpoch 27/100\n12/12 [==============================] - 0s 997us/step - loss: 0.6345 - acc: 0.7500\nEpoch 28/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.6005 - acc: 0.7500\nEpoch 29/100\n12/12 [==============================] - 0s 997us/step - loss: 0.5659 - acc: 0.7500\nEpoch 30/100\n12/12 [==============================] - 0s 997us/step - loss: 0.5398 - acc: 0.7500\nEpoch 31/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.5139 - acc: 0.7500\nEpoch 32/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.4966 - acc: 0.7500\nEpoch 33/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.4640 - acc: 0.7500\nEpoch 34/100\n12/12 [==============================] - 0s 914us/step - loss: 0.4534 - acc: 0.8333\nEpoch 35/100\n12/12 [==============================] - 0s 997us/step - loss: 0.4332 - acc: 0.8333\nEpoch 36/100\n12/12 [==============================] - 0s 997us/step - loss: 0.4194 - acc: 0.8333\nEpoch 37/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.3930 - acc: 0.8333\nEpoch 38/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.3833 - acc: 0.8333\nEpoch 39/100\n12/12 [==============================] - 0s 997us/step - loss: 0.3667 - acc: 0.9167\nEpoch 40/100\n12/12 [==============================] - 0s 997us/step - loss: 0.3488 - acc: 0.9167\nEpoch 41/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.3423 - acc: 0.9167\nEpoch 42/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.3277 - acc: 0.8333\nEpoch 43/100\n12/12 [==============================] - 0s 997us/step - loss: 0.3138 - acc: 0.9167\nEpoch 44/100\n12/12 [==============================] - 0s 997us/step - loss: 0.3072 - acc: 0.9167\nEpoch 45/100\n12/12 [==============================] - 0s 997us/step - loss: 0.2961 - acc: 0.9167\nEpoch 46/100\n12/12 [==============================] - 0s 997us/step - loss: 0.2863 - acc: 0.9167\nEpoch 47/100\n12/12 [==============================] - 0s 914us/step - loss: 0.2756 - acc: 0.9167\nEpoch 48/100\n12/12 [==============================] - 0s 997us/step - loss: 0.2669 - acc: 0.9167\nEpoch 49/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.2608 - acc: 0.9167\nEpoch 50/100\n12/12 [==============================] - 0s 997us/step - loss: 0.2502 - acc: 0.9167\nEpoch 51/100\n12/12 [==============================] - 0s 914us/step - loss: 0.2412 - acc: 1.0000\nEpoch 52/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.2334 - acc: 1.0000\nEpoch 53/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.2263 - acc: 1.0000\nEpoch 54/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.2188 - acc: 1.0000\nEpoch 55/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.2142 - acc: 1.0000\nEpoch 56/100\n12/12 [==============================] - 0s 997us/step - loss: 0.2016 - acc: 1.0000\nEpoch 57/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.1977 - acc: 1.0000\nEpoch 58/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.1903 - acc: 1.0000\nEpoch 59/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.1873 - acc: 1.0000\nEpoch 60/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.1801 - acc: 1.0000\nEpoch 61/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.1738 - acc: 1.0000\nEpoch 62/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.1652 - acc: 1.0000\nEpoch 63/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.1657 - acc: 1.0000\nEpoch 64/100\n12/12 [==============================] - 0s 997us/step - loss: 0.1557 - acc: 1.0000\nEpoch 65/100\n12/12 [==============================] - 0s 997us/step - loss: 0.1561 - acc: 1.0000\nEpoch 66/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.1502 - acc: 1.0000\nEpoch 67/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.1409 - acc: 1.0000\nEpoch 68/100\n12/12 [==============================] - 0s 997us/step - loss: 0.1385 - acc: 1.0000\nEpoch 69/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.1333 - acc: 1.0000\nEpoch 70/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.1309 - acc: 1.0000\nEpoch 71/100\n12/12 [==============================] - 0s 997us/step - loss: 0.1260 - acc: 1.0000\nEpoch 72/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.1208 - acc: 1.0000\nEpoch 73/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.1142 - acc: 1.0000\nEpoch 74/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.1132 - acc: 1.0000\nEpoch 75/100\n12/12 [==============================] - 0s 914us/step - loss: 0.1075 - acc: 1.0000\nEpoch 76/100\n12/12 [==============================] - 0s 997us/step - loss: 0.1055 - acc: 1.0000\nEpoch 77/100\n12/12 [==============================] - 0s 914us/step - loss: 0.0970 - acc: 1.0000\nEpoch 78/100\n12/12 [==============================] - 0s 914us/step - loss: 0.0962 - acc: 1.0000\nEpoch 79/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.0935 - acc: 1.0000\nEpoch 80/100\n12/12 [==============================] - 0s 997us/step - loss: 0.0905 - acc: 1.0000\nEpoch 81/100\n12/12 [==============================] - 0s 997us/step - loss: 0.0855 - acc: 1.0000\nEpoch 82/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.0854 - acc: 1.0000\nEpoch 83/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.0779 - acc: 1.0000\nEpoch 84/100\n12/12 [==============================] - 0s 914us/step - loss: 0.0775 - acc: 1.0000\nEpoch 85/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.0726 - acc: 1.0000\nEpoch 86/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.0685 - acc: 1.0000\nEpoch 87/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.0683 - acc: 1.0000\nEpoch 88/100\n12/12 [==============================] - 0s 997us/step - loss: 0.0637 - acc: 1.0000\nEpoch 89/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.0616 - acc: 1.0000\nEpoch 90/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.0617 - acc: 1.0000\nEpoch 91/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.0570 - acc: 1.0000\nEpoch 92/100\n12/12 [==============================] - 0s 2ms/step - loss: 0.0543 - acc: 1.0000\nEpoch 93/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.0493 - acc: 1.0000\nEpoch 94/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.0507 - acc: 1.0000\nEpoch 95/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.0480 - acc: 1.0000\nEpoch 96/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.0449 - acc: 1.0000\nEpoch 97/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.0453 - acc: 1.0000\nEpoch 98/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.0392 - acc: 1.0000\nEpoch 99/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.0387 - acc: 1.0000\nEpoch 100/100\n12/12 [==============================] - 0s 1ms/step - loss: 0.0366 - acc: 1.0000\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x200ffe70208>"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = build_model()\n",
    "\n",
    "# 훈련 시작\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          epochs=100,\n",
    "          batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[3.73540843e-09, 5.81029580e-09, 4.90806062e-09, 3.86591215e-04,\n        9.35634792e-01, 5.19342569e-09, 2.83534929e-09, 2.63734234e-09,\n        3.62371533e-09, 2.42845211e-09, 6.28069043e-02, 4.44245218e-09,\n        3.61509267e-09, 3.26256466e-09, 6.08125683e-09, 4.45682913e-09,\n        3.86131882e-09, 2.79461965e-09, 3.21821991e-09, 1.17171428e-03,\n        4.66669192e-09, 4.93597074e-09, 3.90041643e-09, 4.07089651e-09,\n        2.81788148e-09, 6.17165297e-09],\n       [1.27956419e-08, 2.19287184e-08, 2.27846080e-08, 3.00206547e-03,\n        1.26497254e-01, 2.29877184e-08, 1.72902599e-08, 1.35921612e-08,\n        2.07044302e-08, 1.17046435e-08, 8.68782520e-01, 1.98093968e-08,\n        1.44463872e-08, 1.70049361e-08, 2.72553056e-08, 2.34200623e-08,\n        1.56738711e-08, 1.17746168e-08, 1.76547008e-08, 1.71801948e-03,\n        1.79922672e-08, 2.53601975e-08, 1.59558091e-08, 2.02602575e-08,\n        1.53299258e-08, 2.81715877e-08],\n       [7.84715404e-09, 1.27351223e-08, 1.18884076e-08, 1.34359449e-04,\n        9.79739845e-01, 1.14311600e-08, 7.20030702e-09, 6.97578262e-09,\n        9.43763911e-09, 5.82861803e-09, 1.74019963e-03, 1.15903971e-08,\n        8.30006375e-09, 1.03518829e-08, 1.40033727e-08, 9.71822267e-09,\n        8.10360312e-09, 8.84029383e-09, 8.41326031e-09, 1.83854569e-02,\n        1.09406102e-08, 7.01236136e-09, 6.16276763e-09, 1.15298944e-08,\n        9.66258895e-09, 1.12620526e-08],\n       [9.51390149e-08, 2.77212877e-07, 2.21795673e-07, 1.41408236e-03,\n        4.49984372e-02, 1.46790484e-07, 1.52271284e-07, 1.48811452e-07,\n        2.11283776e-07, 1.12348815e-07, 5.73488011e-04, 2.26189186e-07,\n        1.83722577e-07, 3.38311253e-07, 2.43657610e-07, 1.84549691e-07,\n        1.27558110e-07, 2.58341032e-07, 2.04323868e-07, 9.53009963e-01,\n        1.70235296e-07, 1.20137230e-07, 9.97451579e-08, 2.53857479e-07,\n        2.46400276e-07, 1.53567015e-07],\n       [5.97718354e-14, 6.32180397e-14, 6.79966202e-14, 2.32487913e-08,\n        9.99987006e-01, 8.25157407e-14, 2.23822680e-14, 2.46005456e-14,\n        4.87552334e-14, 2.60149432e-14, 9.87220847e-06, 6.40632228e-14,\n        2.57708266e-14, 3.34125156e-14, 1.29837276e-13, 5.43098484e-14,\n        4.99900312e-14, 3.92579103e-14, 2.90119186e-14, 3.07956816e-06,\n        8.10042070e-14, 4.53197084e-14, 2.90884328e-14, 5.26774770e-14,\n        2.55051039e-14, 9.84901586e-14],\n       [4.59783951e-14, 5.25855469e-14, 5.22951840e-14, 2.70139768e-08,\n        9.99987483e-01, 6.42374879e-14, 1.68750952e-14, 1.85362132e-14,\n        3.70948626e-14, 2.04516867e-14, 9.39029906e-06, 5.19005920e-14,\n        2.04616750e-14, 2.56534330e-14, 1.00098268e-13, 4.14641635e-14,\n        3.98259137e-14, 3.21308633e-14, 2.35410937e-14, 3.14756176e-06,\n        6.36629895e-14, 3.48710691e-14, 2.25638921e-14, 4.07009733e-14,\n        2.00011042e-14, 7.35041029e-14],\n       [2.31361574e-09, 6.24345109e-09, 1.48183565e-09, 9.99952793e-01,\n        8.35541485e-08, 1.92776684e-09, 1.14840726e-09, 1.74270209e-09,\n        2.67440803e-09, 2.53456234e-09, 4.40929543e-05, 4.91555641e-09,\n        2.07975859e-09, 2.74061995e-09, 2.99013769e-09, 1.65387037e-09,\n        2.40118170e-09, 7.99119437e-09, 3.39566486e-09, 2.93910534e-06,\n        1.79467385e-09, 1.40907219e-09, 2.39419840e-09, 1.87873339e-09,\n        2.39582465e-09, 1.60378133e-09],\n       [1.61805946e-09, 4.35262537e-09, 8.95812813e-10, 9.99969959e-01,\n        9.31591302e-08, 1.34753952e-09, 7.84805443e-10, 1.18382248e-09,\n        1.67100234e-09, 1.64767078e-09, 2.71485133e-05, 3.45330564e-09,\n        1.55863900e-09, 1.69138015e-09, 1.93134775e-09, 1.07034337e-09,\n        1.75497716e-09, 5.62876279e-09, 2.21013652e-09, 2.73715273e-06,\n        1.23454991e-09, 8.80062689e-10, 1.65799841e-09, 1.25421373e-09,\n        1.56747859e-09, 1.01312370e-09],\n       [4.16887390e-14, 4.54860826e-14, 4.58893753e-14, 2.22073169e-08,\n        9.99989271e-01, 5.31575279e-14, 1.36543253e-14, 1.59588664e-14,\n        2.99953882e-14, 1.70690624e-14, 7.87893168e-06, 4.10446078e-14,\n        1.82087452e-14, 2.07208433e-14, 8.39995662e-14, 3.47304786e-14,\n        3.46391820e-14, 2.53493837e-14, 1.87380103e-14, 2.91584729e-06,\n        5.35790420e-14, 2.88726528e-14, 2.09152086e-14, 3.35087047e-14,\n        1.63065921e-14, 6.77707063e-14],\n       [4.13285908e-14, 4.87543220e-14, 4.86903845e-14, 2.28237980e-08,\n        9.99987364e-01, 6.07337463e-14, 1.46539004e-14, 1.74730446e-14,\n        3.25539122e-14, 1.95714196e-14, 9.41722919e-06, 4.30762840e-14,\n        1.75639634e-14, 2.42795642e-14, 8.93708596e-14, 3.77738578e-14,\n        3.70684081e-14, 2.49994964e-14, 2.09582972e-14, 3.21200810e-06,\n        5.66598736e-14, 3.30258451e-14, 2.17447672e-14, 3.67954467e-14,\n        1.76465000e-14, 6.74752070e-14],\n       [9.27534103e-08, 1.72418112e-07, 8.76453115e-08, 9.73969817e-01,\n        4.26149054e-04, 1.21293709e-07, 8.53497326e-08, 7.42935740e-08,\n        1.06483171e-07, 8.85035618e-08, 2.50740442e-02, 1.36435332e-07,\n        9.91466962e-08, 1.22023252e-07, 1.13119647e-07, 8.82207587e-08,\n        8.64833893e-08, 1.49115579e-07, 1.27635602e-07, 5.27445518e-04,\n        9.22537424e-08, 7.35282342e-08, 8.61260219e-08, 1.00234701e-07,\n        9.73464935e-08, 7.64144019e-08],\n       [9.62727142e-08, 1.15264235e-07, 1.29994874e-07, 2.19204649e-02,\n        6.50051655e-03, 1.15181820e-07, 1.10728926e-07, 8.66658141e-08,\n        9.49777572e-08, 6.55073151e-08, 9.71383095e-01, 9.67982103e-08,\n        9.13507137e-08, 1.04213029e-07, 1.29390301e-07, 1.31363251e-07,\n        8.67021868e-08, 6.29312353e-08, 9.21814021e-08, 1.93488828e-04,\n        9.28848962e-08, 1.12999473e-07, 1.06817737e-07, 1.15848081e-07,\n        8.97795189e-08, 1.55364347e-07]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "# 훈련셋 데이터 예측\n",
    "# 26개 캐릭터의 원핫인코딩 형식\n",
    "results = model.predict(x_train)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([ 4, 10,  4, 19,  4,  4,  3,  3,  4,  4,  3, 10], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "# 1축을 기준으로 최대값의 인덱스 구함\n",
    "results = np.argmax(results, 1) \n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "lov -> love\nloo -> look\nfac -> face\nfas -> fast\nhom -> home\nhop -> hope\ngoo -> good\ngol -> gold\ntre -> tree\ntru -> true\nroa -> road\nroc -> rock\n"
    }
   ],
   "source": [
    "# 예측 결과 출력\n",
    "for i, word in enumerate(word_list):\n",
    "    last_char = char_list[results[i]]\n",
    "    print(word[:3] + ' -> ' + word[:3] + last_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}